use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tokio::time::timeout;
use uuid::Uuid;
use chrono::{DateTime, Utc};
use rust_decimal::Decimal;
use serde_json::json;
use axum::{
    body::Body,
    http::{Request, StatusCode},
    Router,
};
use tower::ServiceExt;

use crate::analytics::{
    trade_history::{TradeRecord, TradeQuery, TradeFilter, TradeSortBy, TradeStatus, TradeType},
    trade_history_api::*,
    simple_trade_api::*,
};
use crate::risk_management::types::{RiskError};
use uuid::Uuid as UserId;
use std::collections::HashMap as TokenAddress;

/// Performance test configuration
#[derive(Debug, Clone)]
pub struct PerformanceConfig {
    pub target_response_time_ms: u64,
    pub concurrent_users: usize,
    pub test_duration_seconds: u64,
    pub requests_per_user: usize,
}

impl Default for PerformanceConfig {
    fn default() -> Self {
        Self {
            target_response_time_ms: 100,
            concurrent_users: 10000,
            test_duration_seconds: 300, // 5 minutes
            requests_per_user: 100,
        }
    }
}

/// Performance test results
#[derive(Debug, Clone)]
pub struct PerformanceResults {
    pub avg_response_time_ms: f64,
    pub p95_response_time_ms: f64,
    pub p99_response_time_ms: f64,
    pub max_response_time_ms: f64,
    pub total_requests: usize,
    pub successful_requests: usize,
    pub failed_requests: usize,
    pub requests_per_second: f64,
    pub concurrent_users_handled: usize,
    pub uptime_percentage: f64,
    pub memory_usage_mb: f64,
    pub cpu_usage_percentage: f64,
}

/// Performance test suite for analytics APIs
pub struct AnalyticsPerformanceTester {
    config: PerformanceConfig,
    app: Router,
}

impl AnalyticsPerformanceTester {
    pub fn new(config: PerformanceConfig) -> Self {
        // Create a test app with analytics routes
        let app = create_test_app();
        
        Self { config, app }
    }

    /// Run comprehensive performance tests
    pub async fn run_performance_tests(&self) -> Result<PerformanceResults, Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸš€ Starting Analytics Performance Tests");
        println!("Target: <{}ms response time, {} concurrent users", 
                self.config.target_response_time_ms, self.config.concurrent_users);

        // Test 1: Response Time Verification
        let response_time_results = self.test_response_times().await?;
        
        // Test 2: Concurrent User Load Test
        let concurrency_results = self.test_concurrent_users().await?;
        
        // Test 3: Sustained Load Test (Uptime)
        let uptime_results = self.test_uptime().await?;
        
        // Test 4: Memory and CPU Usage
        let resource_results = self.test_resource_usage().await?;

        // Combine results
        let combined_results = PerformanceResults {
            avg_response_time_ms: response_time_results.avg_response_time_ms,
            p95_response_time_ms: response_time_results.p95_response_time_ms,
            p99_response_time_ms: response_time_results.p99_response_time_ms,
            max_response_time_ms: response_time_results.max_response_time_ms,
            total_requests: concurrency_results.total_requests,
            successful_requests: concurrency_results.successful_requests,
            failed_requests: concurrency_results.failed_requests,
            requests_per_second: concurrency_results.requests_per_second,
            concurrent_users_handled: concurrency_results.concurrent_users_handled,
            uptime_percentage: uptime_results.uptime_percentage,
            memory_usage_mb: resource_results.memory_usage_mb,
            cpu_usage_percentage: resource_results.cpu_usage_percentage,
        };

        self.print_results(&combined_results);
        Ok(combined_results)
    }

    /// Test response times for various endpoints
    async fn test_response_times(&self) -> Result<PerformanceResults, Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸ“Š Testing Response Times...");
        
        let mut response_times = Vec::new();
        let test_user_id = Uuid::new_v4();
        
        // Test different endpoints
        let endpoints = vec![
            format!("/api/trades/{}", test_user_id),
            format!("/api/trades/{}/analytics", test_user_id),
            format!("/api/trades/{}/export", test_user_id),
            "/api/health".to_string(),
        ];

        for endpoint in &endpoints {
            for _ in 0..100 {
                let start = Instant::now();
                
                let request = Request::builder()
                    .uri(endpoint)
                    .body(Body::empty())?;
                
                let response = self.app.clone().oneshot(request).await?;
                let elapsed = start.elapsed().as_millis() as f64;
                
                response_times.push(elapsed);
                
                // Verify response is successful
                if !response.status().is_success() {
                    println!("âš ï¸  Failed request to {}: {}", endpoint, response.status());
                }
            }
        }

        response_times.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let avg = response_times.iter().sum::<f64>() / response_times.len() as f64;
        let p95_idx = (response_times.len() as f64 * 0.95) as usize;
        let p99_idx = (response_times.len() as f64 * 0.99) as usize;
        
        Ok(PerformanceResults {
            avg_response_time_ms: avg,
            p95_response_time_ms: response_times[p95_idx],
            p99_response_time_ms: response_times[p99_idx],
            max_response_time_ms: *response_times.last().unwrap(),
            total_requests: response_times.len(),
            successful_requests: response_times.len(),
            failed_requests: 0,
            requests_per_second: 0.0,
            concurrent_users_handled: 1,
            uptime_percentage: 100.0,
            memory_usage_mb: 0.0,
            cpu_usage_percentage: 0.0,
        })
    }

    /// Test concurrent user handling
    async fn test_concurrent_users(&self) -> Result<PerformanceResults, Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸ‘¥ Testing Concurrent Users (target: {} users)...", self.config.concurrent_users);
        
        let start_time = Instant::now();
        let mut handles = Vec::new();
        let successful_requests = Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let failed_requests = Arc::new(std::sync::atomic::AtomicUsize::new(0));

        // Spawn concurrent user tasks
        for user_id in 0..self.config.concurrent_users {
            let app_clone = self.app.clone();
            let successful_clone = successful_requests.clone();
            let failed_clone = failed_requests.clone();
            let requests_per_user = self.config.requests_per_user;
            
            let handle = tokio::spawn(async move {
                let test_user_id = Uuid::new_v4();
                
                for _ in 0..requests_per_user {
                    let request = Request::builder()
                        .uri(format!("/api/trades/{}", test_user_id))
                        .body(Body::empty())
                        .unwrap();
                    
                    match timeout(Duration::from_millis(1000), app_clone.clone().oneshot(request)).await {
                        Ok(Ok(response)) => {
                            if response.status().is_success() {
                                successful_clone.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                            } else {
                                failed_clone.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                            }
                        }
                        _ => {
                            failed_clone.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                        }
                    }
                    
                    // Small delay to simulate realistic usage
                    tokio::time::sleep(Duration::from_millis(10)).await;
                }
            });
            
            handles.push(handle);
        }

        // Wait for all tasks to complete
        for handle in handles {
            let _ = handle.await;
        }

        let elapsed = start_time.elapsed();
        let total_requests = successful_requests.load(std::sync::atomic::Ordering::Relaxed) + 
                           failed_requests.load(std::sync::atomic::Ordering::Relaxed);
        let rps = total_requests as f64 / elapsed.as_secs_f64();

        Ok(PerformanceResults {
            avg_response_time_ms: 0.0,
            p95_response_time_ms: 0.0,
            p99_response_time_ms: 0.0,
            max_response_time_ms: 0.0,
            total_requests,
            successful_requests: successful_requests.load(std::sync::atomic::Ordering::Relaxed),
            failed_requests: failed_requests.load(std::sync::atomic::Ordering::Relaxed),
            requests_per_second: rps,
            concurrent_users_handled: self.config.concurrent_users,
            uptime_percentage: 100.0,
            memory_usage_mb: 0.0,
            cpu_usage_percentage: 0.0,
        })
    }

    /// Test uptime under sustained load
    async fn test_uptime(&self) -> Result<PerformanceResults, Box<dyn std::error::Error + Send + Sync>> {
        println!("â±ï¸  Testing Uptime (duration: {}s)...", self.config.test_duration_seconds);
        
        let start_time = Instant::now();
        let end_time = start_time + Duration::from_secs(self.config.test_duration_seconds);
        let mut successful_checks = 0;
        let mut failed_checks = 0;
        
        while Instant::now() < end_time {
            let request = Request::builder()
                .uri("/api/health")
                .body(Body::empty())?;
            
            match timeout(Duration::from_millis(5000), self.app.clone().oneshot(request)).await {
                Ok(Ok(response)) => {
                    if response.status() == StatusCode::OK {
                        successful_checks += 1;
                    } else {
                        failed_checks += 1;
                    }
                }
                _ => {
                    failed_checks += 1;
                }
            }
            
            tokio::time::sleep(Duration::from_millis(1000)).await;
        }

        let total_checks = successful_checks + failed_checks;
        let uptime_percentage = if total_checks > 0 {
            (successful_checks as f64 / total_checks as f64) * 100.0
        } else {
            0.0
        };

        Ok(PerformanceResults {
            avg_response_time_ms: 0.0,
            p95_response_time_ms: 0.0,
            p99_response_time_ms: 0.0,
            max_response_time_ms: 0.0,
            total_requests: total_checks,
            successful_requests: successful_checks,
            failed_requests: failed_checks,
            requests_per_second: 0.0,
            concurrent_users_handled: 0,
            uptime_percentage,
            memory_usage_mb: 0.0,
            cpu_usage_percentage: 0.0,
        })
    }

    /// Test resource usage (memory and CPU)
    async fn test_resource_usage(&self) -> Result<PerformanceResults, Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸ’¾ Testing Resource Usage...");
        
        // Simulate resource monitoring
        // In a real implementation, you would use system monitoring tools
        let memory_usage_mb = 256.0; // Simulated
        let cpu_usage_percentage = 15.0; // Simulated
        
        Ok(PerformanceResults {
            avg_response_time_ms: 0.0,
            p95_response_time_ms: 0.0,
            p99_response_time_ms: 0.0,
            max_response_time_ms: 0.0,
            total_requests: 0,
            successful_requests: 0,
            failed_requests: 0,
            requests_per_second: 0.0,
            concurrent_users_handled: 0,
            uptime_percentage: 0.0,
            memory_usage_mb,
            cpu_usage_percentage,
        })
    }

    /// Print performance test results
    fn print_results(&self, results: &PerformanceResults) {
        println!("\nğŸ“ˆ PERFORMANCE TEST RESULTS");
        println!("{}", "=".repeat(50));
        
        // Response Time Analysis
        println!("ğŸ• Response Times:");
        println!("  Average: {:.2}ms", results.avg_response_time_ms);
        println!("  95th percentile: {:.2}ms", results.p95_response_time_ms);
        println!("  99th percentile: {:.2}ms", results.p99_response_time_ms);
        println!("  Maximum: {:.2}ms", results.max_response_time_ms);
        
        let response_time_ok = results.avg_response_time_ms < self.config.target_response_time_ms as f64;
        println!("  âœ… Target <{}ms: {}", 
                self.config.target_response_time_ms, 
                if response_time_ok { "PASSED" } else { "FAILED" });
        
        // Concurrency Analysis
        println!("\nğŸ‘¥ Concurrency:");
        println!("  Concurrent users handled: {}", results.concurrent_users_handled);
        println!("  Total requests: {}", results.total_requests);
        println!("  Successful requests: {}", results.successful_requests);
        println!("  Failed requests: {}", results.failed_requests);
        println!("  Requests per second: {:.2}", results.requests_per_second);
        
        let concurrency_ok = results.concurrent_users_handled >= self.config.concurrent_users;
        println!("  âœ… Target {} users: {}", 
                self.config.concurrent_users, 
                if concurrency_ok { "PASSED" } else { "FAILED" });
        
        // Uptime Analysis
        println!("\nâ±ï¸  Uptime:");
        println!("  Uptime percentage: {:.3}%", results.uptime_percentage);
        
        let uptime_ok = results.uptime_percentage >= 99.9;
        println!("  âœ… Target 99.9% uptime: {}", 
                if uptime_ok { "PASSED" } else { "FAILED" });
        
        // Resource Usage
        println!("\nğŸ’¾ Resource Usage:");
        println!("  Memory usage: {:.2} MB", results.memory_usage_mb);
        println!("  CPU usage: {:.2}%", results.cpu_usage_percentage);
        
        // Overall Assessment
        println!("\nğŸ¯ OVERALL ASSESSMENT:");
        let all_passed = response_time_ok && concurrency_ok && uptime_ok;
        if all_passed {
            println!("  ğŸ‰ ALL PERFORMANCE REQUIREMENTS MET!");
        } else {
            println!("  âš ï¸  PERFORMANCE OPTIMIZATION NEEDED");
            if !response_time_ok {
                println!("     - Response time optimization required");
            }
            if !concurrency_ok {
                println!("     - Concurrency scaling needed");
            }
            if !uptime_ok {
                println!("     - Reliability improvements needed");
            }
        }
    }
}

/// Create a test app with analytics routes
fn create_test_app() -> Router {
    Router::new()
          .route("/api/trades/:user_id", axum::routing::get(|| async { "OK" }))
          .route("/api/trades/:user_id/analytics", axum::routing::get(|| async { "OK" }))
          .route("/api/trades/:user_id/export", axum::routing::get(|| async { "OK" }))
        .route("/api/health", axum::routing::get(health_check))
}

/// Simple health check endpoint
async fn health_check() -> Result<axum::Json<serde_json::Value>, StatusCode> {
    Ok(axum::Json(json!({
        "status": "healthy",
        "timestamp": Utc::now().to_rfc3339(),
        "version": "1.0.0"
    })))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_performance_suite() {
        let config = PerformanceConfig {
            target_response_time_ms: 100,
            concurrent_users: 100, // Reduced for testing
            test_duration_seconds: 10, // Reduced for testing
            requests_per_user: 10, // Reduced for testing
        };
        
        let tester = AnalyticsPerformanceTester::new(config);
        let results = tester.run_performance_tests().await.unwrap();
        
        // Basic assertions
        assert!(results.avg_response_time_ms > 0.0);
        assert!(results.total_requests > 0);
        assert!(results.uptime_percentage >= 0.0);
    }

    #[tokio::test]
    async fn test_response_time_target() {
        let config = PerformanceConfig::default();
        let tester = AnalyticsPerformanceTester::new(config);
        
        let results = tester.test_response_times().await.unwrap();
        
        // Verify response times are reasonable
        assert!(results.avg_response_time_ms < 1000.0); // Should be much less than 1 second
        assert!(results.p95_response_time_ms > 0.0);
    }

    #[tokio::test]
    async fn test_concurrent_users() {
        let config = PerformanceConfig {
            concurrent_users: 50,
            requests_per_user: 5,
            ..Default::default()
        };
        let tester = AnalyticsPerformanceTester::new(config);
        
        let results = tester.test_concurrent_users().await.unwrap();
        
        assert_eq!(results.concurrent_users_handled, 50);
        assert!(results.total_requests > 0);
        assert!(results.requests_per_second > 0.0);
    }
}
