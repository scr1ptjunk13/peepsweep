use serde::{Deserialize, Serialize};
use rustc_hash::FxHashMap;
use std::time::SystemTime;
use crate::types::Chain;

/// Token information structure
#[derive(Debug, Clone)]
pub struct TokenInfo {
    pub address: &'static str,        // Lowercase hex address
    pub chain_id: u64,               // Chain identifier  
    pub symbol: &'static str,         // Token symbol (e.g., "ETH")
    pub name: &'static str,           // Full name (e.g., "Ethereum")
    pub decimals: u8,                 // Token decimals
    pub logo_uri: Option<&'static str>, // Logo URL
    pub verified: bool,               // Verified by major lists
    pub market_cap_usd: Option<f64>,  // Market cap for ranking
    pub price_usd: Option<f64>,       // Current price
    pub tags: &'static [&'static str], // Categories (stablecoin, defi, etc.)
}

// For extended tokens that need to be serializable
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtendedTokenInfo {
    pub address: String,              // Lowercase hex address
    pub chain_id: u64,               // Chain identifier  
    pub symbol: String,               // Token symbol (e.g., "ETH")
    pub name: String,                 // Full name (e.g., "Ethereum")
    pub decimals: u8,                 // Token decimals
    pub logo_uri: Option<String>,     // Logo URL
    pub verified: bool,               // Verified by major lists
    pub market_cap_usd: Option<f64>,  // Market cap for ranking
    pub price_usd: Option<f64>,       // Current price
    pub tags: Vec<String>,            // Categories (stablecoin, defi, etc.)
}

// Conversion methods
impl From<&TokenInfo> for ExtendedTokenInfo {
    fn from(token: &TokenInfo) -> Self {
        Self {
            address: token.address.to_string(),
            chain_id: token.chain_id,
            symbol: token.symbol.to_string(),
            name: token.name.to_string(),
            decimals: token.decimals,
            logo_uri: token.logo_uri.map(|s| s.to_string()),
            verified: token.verified,
            market_cap_usd: token.market_cap_usd,
            price_usd: token.price_usd,
            tags: token.tags.iter().map(|s| s.to_string()).collect(),
        }
    }
}

// ExtendedTokenInfo methods can be added here if needed

/// Search result with relevance scoring
#[derive(Debug, Clone)]
pub struct SearchResult {
    pub token: ExtendedTokenInfo,  // Use ExtendedTokenInfo to avoid lifetime issues
    pub score: u32,                // Relevance score (0-100)
}

impl SearchResult {
    pub fn new(token: ExtendedTokenInfo, score: u32) -> Self {
        Self { token, score }
    }
    
    pub fn from_static_token(token: &TokenInfo, score: u32) -> Self {
        Self {
            token: ExtendedTokenInfo::from(token),
            score,
        }
    }
}

/// Main token database with two-tier storage
pub struct TokenDatabase {
    // Core tokens (top 1000) - PHF for maximum speed
    core_tokens: &'static phf::Map<&'static str, TokenInfo>,
    
    // Extended tokens - FxHashMap for good performance  
    extended_tokens: FxHashMap<String, ExtendedTokenInfo>,
    
    // Search indices for fuzzy matching
    symbol_index: FxHashMap<String, Vec<String>>, // symbol -> addresses
    name_index: FxHashMap<String, Vec<String>>,   // name -> addresses
    
    // Chain-specific lookups
    chain_tokens: FxHashMap<u64, Vec<String>>,    // chain_id -> addresses
    
    // Metadata
    last_updated: SystemTime,
    total_tokens: usize,
}

impl TokenDatabase {
    /// Initialize token database with embedded core tokens
    pub fn new() -> Self {
        let mut db = Self {
            core_tokens: &CORE_TOKENS,  // Will be generated by build.rs
            extended_tokens: FxHashMap::default(),
            symbol_index: FxHashMap::default(),
            name_index: FxHashMap::default(),
            chain_tokens: FxHashMap::default(),
            last_updated: SystemTime::now(),
            total_tokens: 0,
        };
        
        // Build search indices from core tokens
        db.build_search_indices();
        
        // Try to load cached extended tokens
        if let Ok(cached) = Self::load_cached_tokens() {
            db.extended_tokens = cached;
            db.rebuild_search_indices();
        }
        
        db
    }
    
    /// Get token by exact address and chain
    pub fn get_token(&self, address: &str, chain_id: u64) -> Option<ExtendedTokenInfo> {
        let key = format!("{}:{}", address.to_lowercase(), chain_id);
        self.get_token_by_key_unified(&key)
    }
    
    /// Search tokens with fuzzy matching and ranking
    pub fn search(&self, query: &str, chain_id: Option<u64>, limit: usize) -> Vec<SearchResult> {
        let query_lower = query.to_lowercase();
        let mut results = Vec::new();
        
        // 1. Exact symbol matches (score: 100)
        if let Some(addresses) = self.symbol_index.get(&query_lower) {
            for addr in addresses {
                if let Some(token) = self.get_token_by_key_unified(addr) {
                    if chain_id.map_or(true, |c| c == token.chain_id) {
                        results.push(SearchResult::new(token, 100));
                    }
                }
            }
        }
        
        // 2. Symbol prefix matches (score: 90)
        for (symbol, addresses) in &self.symbol_index {
            if symbol.starts_with(&query_lower) && symbol != &query_lower {
                for addr in addresses {
                    if let Some(token) = self.get_token_by_key_unified(addr) {
                        if chain_id.map_or(true, |c| c == token.chain_id) {
                            results.push(SearchResult::new(token, 90));
                        }
                    }
                }
            }
        }
        
        // 3. Name contains matches (score: 80)
        for (name, addresses) in &self.name_index {
            if name.contains(&query_lower) {
                for addr in addresses {
                    if let Some(token) = self.get_token_by_key_unified(addr) {
                        if chain_id.map_or(true, |c| c == token.chain_id) {
                            results.push(SearchResult::new(token, 80));
                        }
                    }
                }
            }
        }
        
        // 4. Address prefix matches (score: 70)
        if query_lower.starts_with("0x") && query_lower.len() >= 4 {
            // Search through core tokens
            for token in self.core_tokens.values() {
                if token.address.to_lowercase().starts_with(&query_lower) {
                    if chain_id.map_or(true, |c| c == token.chain_id) {
                        results.push(SearchResult::from_static_token(token, 70));
                    }
                }
            }
            // Search through extended tokens
            for token in self.extended_tokens.values() {
                if token.address.to_lowercase().starts_with(&query_lower) {
                    if chain_id.map_or(true, |c| c == token.chain_id) {
                        results.push(SearchResult::new(token.clone(), 70));
                    }
                }
            }
        }
        
        // Sort by score, then by market cap, then by verification
        results.sort_by(|a, b| {
            b.score.cmp(&a.score)
                .then_with(|| {
                    b.token.market_cap_usd
                        .partial_cmp(&a.token.market_cap_usd)
                        .unwrap_or(std::cmp::Ordering::Equal)
                })
                .then_with(|| b.token.verified.cmp(&a.token.verified))
        });
        
        // Remove duplicates by keeping highest scoring entry for each address+chain
        let mut unique_results = Vec::new();
        let mut seen = std::collections::HashSet::new();
        
        for result in results {
            let key = (result.token.address.clone(), result.token.chain_id);
            if !seen.contains(&key) {
                seen.insert(key);
                unique_results.push(result);
            }
        }
        
        unique_results.truncate(limit);
        
        unique_results
    }
    
    /// Get tokens for a specific chain
    pub fn get_chain_tokens(&self, chain_id: u64) -> Vec<ExtendedTokenInfo> {
        if let Some(addresses) = self.chain_tokens.get(&chain_id) {
            addresses.iter()
                .filter_map(|addr| self.get_token_by_key_unified(addr))
                .collect()
        } else {
            Vec::new()
        }
    }
    
    /// Get popular tokens for a chain (top 20 by market cap)
    pub fn get_popular_tokens(&self, chain_id: u64) -> Vec<ExtendedTokenInfo> {
        let mut tokens = self.get_chain_tokens(chain_id);
        
        // Sort by market cap descending
        tokens.sort_by(|a, b| {
            b.market_cap_usd
                .partial_cmp(&a.market_cap_usd)
                .unwrap_or(std::cmp::Ordering::Equal)
        });
        
        tokens.truncate(20);
        tokens
    }
    
    /// Convert Chain enum to chain_id
    pub fn chain_to_id(chain: &Chain) -> u64 {
        match chain {
            Chain::Ethereum => 1,
            Chain::Polygon => 137,
            Chain::Arbitrum => 42161,
            Chain::Optimism => 10,
            Chain::Base => 8453,
            Chain::Avalanche => 43114,
            Chain::BNB => 56,
            Chain::Fantom => 250,
        }
    }
    
    /// Helper: Get token by internal key format
    fn get_token_by_key(&self, key: &str) -> Option<&TokenInfo> {
        // Try core tokens first
        if let Some(token) = self.core_tokens.get(key) {
            return Some(token);
        }
        
        // Extended tokens don't match this signature
        None
    }
    
    /// Helper: Get token by key as ExtendedTokenInfo (unified interface)
    fn get_token_by_key_unified(&self, key: &str) -> Option<ExtendedTokenInfo> {
        // Try core tokens first
        if let Some(token) = self.core_tokens.get(key) {
            return Some(ExtendedTokenInfo::from(token));
        }
        
        // Try extended tokens
        self.extended_tokens.get(key).cloned()
    }
    
    /// Helper: Get all core tokens iterator
    fn all_core_tokens(&self) -> impl Iterator<Item = &TokenInfo> {
        self.core_tokens.values()
    }
    
    /// Build search indices from current tokens
    fn build_search_indices(&mut self) {
        self.symbol_index.clear();
        self.name_index.clear();
        self.chain_tokens.clear();
        
        // Index core tokens
        for (key, token) in self.core_tokens.entries() {
            self.index_token(key, token);
        }
        
        // Index extended tokens (collect to avoid borrow conflict)
        let extended_items: Vec<_> = self.extended_tokens.iter()
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect();
        for (key, token) in extended_items {
            self.index_extended_token(&key, &token);
        }
        
        self.total_tokens = self.core_tokens.len() + self.extended_tokens.len();
    }
    
    /// Rebuild search indices (after adding extended tokens)
    fn rebuild_search_indices(&mut self) {
        self.build_search_indices();
    }
    
    /// Index a single token
    fn index_token(&mut self, key: &str, token: &TokenInfo) {
        let symbol_lower = token.symbol.to_lowercase();
        let name_lower = token.name.to_lowercase();
        
        // Symbol index
        self.symbol_index
            .entry(symbol_lower)
            .or_insert_with(Vec::new)
            .push(key.to_string());
            
        // Name index (for partial matches)
        self.name_index
            .entry(name_lower)
            .or_insert_with(Vec::new)
            .push(key.to_string());
            
        // Chain index
        self.chain_tokens
            .entry(token.chain_id)
            .or_insert_with(Vec::new)
            .push(key.to_string());
    }
    
    /// Index an extended token
    fn index_extended_token(&mut self, key: &str, token: &ExtendedTokenInfo) {
        let symbol_lower = token.symbol.to_lowercase();
        let name_lower = token.name.to_lowercase();
        
        // Symbol index
        self.symbol_index
            .entry(symbol_lower)
            .or_insert_with(Vec::new)
            .push(key.to_string());
            
        // Name index (for partial matches)
        self.name_index
            .entry(name_lower)
            .or_insert_with(Vec::new)
            .push(key.to_string());
            
        // Chain index
        self.chain_tokens
            .entry(token.chain_id)
            .or_insert_with(Vec::new)
            .push(key.to_string());
    }
    
    /// Load cached extended tokens from disk
    fn load_cached_tokens() -> Result<FxHashMap<String, ExtendedTokenInfo>, Box<dyn std::error::Error>> {
        // TODO: Implement caching mechanism
        // For now, return empty map
        Ok(FxHashMap::default())
    }
}

// This will be generated by build.rs
include!(concat!(env!("OUT_DIR"), "/core_tokens.rs"));

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_token_database_creation() {
        let db = TokenDatabase::new();
        assert!(db.total_tokens > 0, "Database should have tokens loaded");
        println!("✅ Database created with {} tokens", db.total_tokens);
    }
    
    #[test]
    fn test_chain_id_conversion() {
        assert_eq!(TokenDatabase::chain_to_id(&Chain::Ethereum), 1);
        assert_eq!(TokenDatabase::chain_to_id(&Chain::Polygon), 137);
        assert_eq!(TokenDatabase::chain_to_id(&Chain::Arbitrum), 42161);
        assert_eq!(TokenDatabase::chain_to_id(&Chain::Optimism), 10);
        assert_eq!(TokenDatabase::chain_to_id(&Chain::Base), 8453);
        println!("✅ Chain ID conversion working correctly");
    }
    
    #[test]
    fn test_token_search_functionality() {
        let db = TokenDatabase::new();
        
        // Test ETH search
        let eth_results = db.search("eth", Some(1), 5);
        assert!(!eth_results.is_empty(), "ETH search should return results");
        
        // Verify ETH is in results with high score
        let has_eth = eth_results.iter().any(|r| r.token.symbol.to_lowercase() == "eth" && r.score >= 90);
        assert!(has_eth, "ETH should be found with high score");
        
        println!("✅ ETH search returned {} results", eth_results.len());
        
        // Test USDC search
        let usdc_results = db.search("usdc", Some(1), 3);
        assert!(!usdc_results.is_empty(), "USDC search should return results");
        
        // Verify USDC exact match
        let has_usdc = usdc_results.iter().any(|r| r.token.symbol == "USDC" && r.score == 100);
        assert!(has_usdc, "USDC should be found with exact match score");
        
        println!("✅ USDC search returned {} results", usdc_results.len());
    }
    
    #[test]
    fn test_direct_token_lookup() {
        let db = TokenDatabase::new();
        
        // Test WETH lookup (should be in embedded tokens)
        let weth = db.get_token("0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2", 1);
        assert!(weth.is_some(), "WETH should be found by address");
        
        let weth_token = weth.unwrap();
        assert_eq!(weth_token.symbol, "WETH");
        assert_eq!(weth_token.chain_id, 1);
        assert!(weth_token.verified, "WETH should be verified");
        
        println!("✅ WETH found: {} - {}", weth_token.symbol, weth_token.name);
        
        // Test USDC lookup
        let usdc = db.get_token("0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48", 1);
        assert!(usdc.is_some(), "USDC should be found by address");
        
        let usdc_token = usdc.unwrap();
        assert_eq!(usdc_token.symbol, "USDC");
        assert_eq!(usdc_token.decimals, 6);
        
        println!("✅ USDC found: {} - {} decimals", usdc_token.symbol, usdc_token.decimals);
    }
    
    #[test]
    fn test_search_scoring_system() {
        let db = TokenDatabase::new();
        
        // Test that results are properly scored and sorted
        let results = db.search("eth", Some(1), 10);
        
        // Results should be sorted by score (descending)
        let mut prev_score = u32::MAX;
        for result in &results {
            assert!(result.score <= prev_score, 
                "Results should be sorted by score descending: {} <= {}", 
                result.score, prev_score);
            prev_score = result.score;
        }
        
        // Test specific scoring: exact symbol match should get 100
        let usdc_results = db.search("USDC", Some(1), 5);
        let exact_usdc = usdc_results.iter().find(|r| r.token.symbol == "USDC");
        if let Some(usdc) = exact_usdc {
            assert_eq!(usdc.score, 100, "Exact symbol match should get score 100");
        }
        
        println!("✅ Search scoring system working correctly");
        println!("   ETH search results:");
        for (i, result) in results.iter().take(3).enumerate() {
            println!("   {}. {} - Score: {}", i + 1, result.token.symbol, result.score);
        }
    }
    
    #[test]
    fn test_chain_filtering() {
        let db = TokenDatabase::new();
        
        // Search without chain filter
        let all_results = db.search("eth", None, 20);
        
        // Search with Ethereum chain filter
        let eth_results = db.search("eth", Some(1), 20);
        
        // All Ethereum results should have chain_id = 1
        for result in &eth_results {
            assert_eq!(result.token.chain_id, 1, "All results should be on Ethereum");
        }
        
        // Ethereum-filtered results should be <= total results
        assert!(eth_results.len() <= all_results.len(), 
            "Chain-filtered results should be subset of all results");
        
        println!("✅ Chain filtering working: {} total, {} on Ethereum", 
            all_results.len(), eth_results.len());
    }
    
    #[test]
    fn test_popular_tokens() {
        let db = TokenDatabase::new();
        
        let popular = db.get_popular_tokens(1); // Ethereum
        assert!(!popular.is_empty(), "Should have popular tokens");
        
        // Verify tokens are sorted by market cap (descending)
        let mut prev_market_cap = f64::INFINITY;
        for token in &popular {
            if let Some(market_cap) = token.market_cap_usd {
                assert!(market_cap <= prev_market_cap, 
                    "Tokens should be sorted by market cap descending");
                prev_market_cap = market_cap;
            }
        }
        
        println!("✅ Popular tokens: {} found, properly sorted", popular.len());
        
        // Print top 3 for verification
        for (i, token) in popular.iter().take(3).enumerate() {
            if let Some(market_cap) = token.market_cap_usd {
                println!("   {}. {} - ${:.1}B", i + 1, token.symbol, market_cap / 1e9);
            } else {
                println!("   {}. {} - No market cap data", i + 1, token.symbol);
            }
        }
    }
    
    #[test]
    fn test_address_prefix_search() {
        let db = TokenDatabase::new();
        
        // Test searching by address prefix
        let results = db.search("0xc02a", Some(1), 5);
        
        // Should find WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2)
        let has_weth = results.iter().any(|r| 
            r.token.address.starts_with("0xc02a") && r.token.symbol == "WETH"
        );
        
        assert!(has_weth, "Should find WETH by address prefix");
        println!("✅ Address prefix search working");
    }
    
    #[test]
    fn test_case_insensitive_search() {
        let db = TokenDatabase::new();
        
        // Test different cases
        let lower_results = db.search("eth", Some(1), 5);
        let upper_results = db.search("ETH", Some(1), 5);
        let mixed_results = db.search("Eth", Some(1), 5);
        
        // Should return same results regardless of case
        assert_eq!(lower_results.len(), upper_results.len(), 
            "Case should not affect search results");
        assert_eq!(lower_results.len(), mixed_results.len(), 
            "Case should not affect search results");
        
        println!("✅ Case-insensitive search working");
    }
    
    #[test]
    fn test_search_result_deduplication() {
        let db = TokenDatabase::new();
        
        let results = db.search("eth", Some(1), 20);
        
        // Check for duplicates by address + chain_id
        let mut seen = std::collections::HashSet::new();
        for result in &results {
            let key = (&result.token.address, result.token.chain_id);
            assert!(!seen.contains(&key), 
                "Should not have duplicate tokens: {} on chain {}", 
                result.token.address, result.token.chain_id);
            seen.insert(key);
        }
        
        println!("✅ Search result deduplication working: {} unique results", results.len());
    }
    
    #[test]
    fn test_token_verification_status() {
        let db = TokenDatabase::new();
        
        // Get some popular tokens
        let popular = db.get_popular_tokens(1);
        
        // Major tokens should be verified
        let major_tokens = ["ETH", "WETH", "USDC", "USDT"];
        for token_symbol in &major_tokens {
            let token_result = popular.iter().find(|t| t.symbol == *token_symbol);
            if let Some(token) = token_result {
                assert!(token.verified, "{} should be verified", token_symbol);
            }
        }
        
        println!("✅ Token verification status working");
    }
}
